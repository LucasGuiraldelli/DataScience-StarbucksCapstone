{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the json files\n",
    "portfolio = pd.read_json('././Data/portfolio.json', orient='records', lines=True) \n",
    "profile = pd.read_json('././Data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('././Data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# 'channels' column dummies\n",
    "channel_dummies = pd.DataFrame(mlb.fit_transform(portfolio['channels']), columns=mlb.classes_, index=portfolio.index)\n",
    "\n",
    "# 'offer_type' column dummies\n",
    "offer_type_dummies = portfolio['offer_type'].str.get_dummies()\n",
    "\n",
    "# concatenate back to portfolio\n",
    "portfolio = pd.concat([portfolio, channel_dummies, offer_type_dummies], axis=1)\n",
    "\n",
    "# drop old columns\n",
    "# portfolio = portfolio.drop(['channels', 'offer_type'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'event' column dummies\n",
    "event_dummies = transcript['event'].str.get_dummies()\n",
    "\n",
    "transcript = pd.concat([transcript, event_dummies], axis=1).rename(columns={'offer completed': 'offer_completed',\\\n",
    "                                                                             'offer received': 'offer_received', \\\n",
    "                                                                             'offer viewed': 'offer_viewed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate columns for amount and offer_id from value col.\n",
    "transcript['offer_id'] = transcript.value.apply(create_offer_id_col)\n",
    "transcript['amount'] = transcript.value.apply(create_amount_col)\n",
    "\n",
    "# change amount column type to float\n",
    "transcript['amount'] = transcript['amount'].astype('float')\n",
    "\n",
    "# transcript = transcript.drop('value', axis=1)\n",
    "\n",
    "# drop value column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile table\n",
    "profile['became_member_on'] = pd.to_datetime(profile['became_member_on'], format='%Y%m%d')\n",
    "\n",
    "profile['gender'] = profile['gender'].fillna('NA')\n",
    "\n",
    "# treat income NA's with mean value of the column \n",
    "profile['income'] = profile['income'].fillna(profile['income'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_df = pd.read_pickle('/workspace/DataScience-StarbucksCapstone/user_item_matrix.p')\n",
    "train_matrix = pd.read_pickle('/workspace/DataScience-StarbucksCapstone/train_df.p')\n",
    "test_matrix = pd.read_pickle('/workspace/DataScience-StarbucksCapstone/test_df.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Training matrix\n",
      "Processing Offer:  0b1e1539f2cc45b7b9fa7c272da2e1d7\n",
      "finished upto #: 5000 persons\n",
      "finished upto #: 10000 persons\n",
      "finished upto #: 15000 persons\n",
      "Processing Offer:  2298d6c36e964ae4a3e7e9706d1fb8c2\n",
      "finished upto #: 5000 persons\n",
      "finished upto #: 10000 persons\n",
      "finished upto #: 15000 persons\n",
      "Processing Offer:  2906b810c7d4411798c6938adc9daaa5\n",
      "finished upto #: 5000 persons\n",
      "finished upto #: 10000 persons\n",
      "finished upto #: 15000 persons\n",
      "Processing Offer:  4d5c57ea9a6940dd891ad53e9dbe8da0\n",
      "finished upto #: 5000 persons\n",
      "finished upto #: 10000 persons\n",
      "finished upto #: 15000 persons\n",
      "Processing Offer:  9b98b8c7a33c4b65b9aebfe6a799e6d9\n",
      "finished upto #: 5000 persons\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_df,test_df,train_matrix, test_matrix  \u001b[39m=\u001b[39muser_item_train_test_split(transcript)\n",
      "Cell \u001b[0;32mIn[18], line 29\u001b[0m, in \u001b[0;36muser_item_train_test_split\u001b[0;34m(transcript_df, training_perc)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m#converting both into user_item_matrix format\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPreparing Training matrix\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m train_matrix \u001b[39m=\u001b[39m create_user_item_matrix(training_df, \u001b[39m'\u001b[39;49m\u001b[39mtrain_df.p\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPreparing Testing matrix\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m test_matrix \u001b[39m=\u001b[39m create_user_item_matrix(test_df, \u001b[39m'\u001b[39m\u001b[39mtest_df.p\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 31\u001b[0m, in \u001b[0;36mcreate_user_item_matrix\u001b[0;34m(offers_given, filename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinished upto #:\u001b[39m\u001b[39m\"\u001b[39m, num, \u001b[39m'\u001b[39m\u001b[39mpersons\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m events \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m offers_given[(offers_given[\u001b[39m'\u001b[39m\u001b[39moffer_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39moffer_id) \u001b[39m&\u001b[39m (offers_given[\u001b[39m'\u001b[39;49m\u001b[39mperson\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m==\u001b[39;49mperson)][\u001b[39m'\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     32\u001b[0m     events\u001b[39m.\u001b[39mappend(event)\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(events) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6245\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    286\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_df,test_df,train_matrix, test_matrix=user_item_train_test_split(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit FunkSVD with the specified hyper parameters to the training data\n",
    "np_train=np.matrix(train_matrix)\n",
    "\n",
    "user_mat_20, offer_mat_20 = FunkSVD(np_train, latent_features=20, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for the best number of latent feature. (with latent features 10)\n",
    "user_mat_15, offer_mat_15 = FunkSVD(np_train, latent_features=15, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for the best number of latent feature. (with latent features 10)\n",
    "user_mat_10, offer_mat_10 = FunkSVD(np_train, latent_features=10, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for the best number of latent feature. (with latent features 5)\n",
    "user_mat_5, offer_mat_5 = FunkSVD(np_train, latent_features=5, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Check performance of the FUNKSVD models with the various number of latent features against the test dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for latent features of 20\n",
    "validation_score(test_matrix, user_mat_20, offer_mat_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for latent features of 15\n",
    "validation_score(test_matrix, user_mat_15, offer_mat_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for latent features of 10\n",
    "validation_score(test_matrix, user_mat_10, offer_mat_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for latent features of 5\n",
    "validation_score(test_matrix, user_mat_5, offer_mat_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the validation scores the model using latent featues of 5 seems to be performing the best."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recomendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our training dataset only consists of some users, we need to have a recommendation engine that can also handle a new user. Below functions will help make default offer recommendations to a new Customer by recommending offer which generated the maximum reactions from existing Customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_reactions=offer_max_reactions(all_df)\n",
    "offer_reactions=offer_reactions.merge(portfolio[['id','offer_type']], left_on='offer_id',right_on='id', how='left').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_reactions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = {\"bogo\": \"#273c75\", \"discount\": \"#44bd32\"}\n",
    "offer_reactions['Total_reactions'].plot(\n",
    "        kind=\"bar\", color=offer_reactions['offer_type'].replace(colours)\n",
    ").legend(\n",
    "    [\n",
    "        Patch(facecolor=colours['bogo']),\n",
    "        Patch(facecolor=colours['discount'])\n",
    "    ], [\"bogo\", \"discount\"]\n",
    ")\n",
    "plt.title('Offer count of total reactions')\n",
    "plt.xlabel('Offer index number')\n",
    "plt.ylabel('Total Reactions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above chart it is clear that discount is the best performing offer in the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Next steps and improvements\n",
    "In order to improve the above recommendation engine, I would suggest the following approaches.\n",
    "\n",
    "The default recommendation for new users can be improved by accounting for demographic information such as gender, age, etc assuming such information is available to us\n",
    "Alternatively algorithms apart from Funk SVD or neural networks can be explored\n",
    "7.Credits and references\n",
    "Starbucks and Udacity for dataset\n",
    "https://stackoverflow.com/questions\n",
    "Udacity implementing 'Matrix factorization for Recommendations' lesson for function implementations such as FunkSVD, User item matrix creations, prediction and validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
